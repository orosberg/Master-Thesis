{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from combat.pycombat import pycombat\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_files(path, starts_with, ends_with = \".csv\"):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(starts_with) and filename.endswith(ends_with):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            file_list.append(pd.read_csv(file_path))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_shape(dfs : list):\n",
    "    return all(df.shape == dfs[0].shape for df in dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_from_m_datasets(dfs : list):\n",
    "    if not same_shape:\n",
    "        print(\"Dataframes must have the same shape\")\n",
    "    joined = pd.concat(dfs).reset_index()\n",
    "    return joined.groupby('index').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P02768</th>\n",
       "      <th>P02787</th>\n",
       "      <th>P01009</th>\n",
       "      <th>P01024</th>\n",
       "      <th>P0C0L5</th>\n",
       "      <th>P02649</th>\n",
       "      <th>P0DOY2</th>\n",
       "      <th>P00738</th>\n",
       "      <th>P06396</th>\n",
       "      <th>P02647</th>\n",
       "      <th>...</th>\n",
       "      <th>Q9NVA2</th>\n",
       "      <th>Q08257</th>\n",
       "      <th>Q56P03</th>\n",
       "      <th>Q9UJ90</th>\n",
       "      <th>P31948</th>\n",
       "      <th>P05107</th>\n",
       "      <th>O95196</th>\n",
       "      <th>O75339</th>\n",
       "      <th>O14960</th>\n",
       "      <th>Q07812</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.072897</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>0.402426</td>\n",
       "      <td>0.184709</td>\n",
       "      <td>0.701173</td>\n",
       "      <td>-0.137677</td>\n",
       "      <td>-0.193675</td>\n",
       "      <td>0.659157</td>\n",
       "      <td>0.227605</td>\n",
       "      <td>-0.337082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768857</td>\n",
       "      <td>0.558457</td>\n",
       "      <td>0.379343</td>\n",
       "      <td>0.441253</td>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.524307</td>\n",
       "      <td>2.072155</td>\n",
       "      <td>0.279783</td>\n",
       "      <td>0.679007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028010</td>\n",
       "      <td>-0.133621</td>\n",
       "      <td>-0.309150</td>\n",
       "      <td>-0.044071</td>\n",
       "      <td>0.438521</td>\n",
       "      <td>-0.164236</td>\n",
       "      <td>0.063932</td>\n",
       "      <td>0.849340</td>\n",
       "      <td>0.121026</td>\n",
       "      <td>-0.203564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377361</td>\n",
       "      <td>0.403682</td>\n",
       "      <td>0.216778</td>\n",
       "      <td>0.722584</td>\n",
       "      <td>0.270382</td>\n",
       "      <td>-0.243587</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>1.936260</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>1.361930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.081855</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.072067</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>-0.154194</td>\n",
       "      <td>0.247885</td>\n",
       "      <td>-0.479686</td>\n",
       "      <td>-0.306355</td>\n",
       "      <td>0.169838</td>\n",
       "      <td>-0.299773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.764546</td>\n",
       "      <td>-0.285425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.390569</td>\n",
       "      <td>0.105446</td>\n",
       "      <td>0.218675</td>\n",
       "      <td>-0.974621</td>\n",
       "      <td>-3.342641</td>\n",
       "      <td>-0.118785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243559</td>\n",
       "      <td>-0.058127</td>\n",
       "      <td>1.359753</td>\n",
       "      <td>-0.065500</td>\n",
       "      <td>-0.440303</td>\n",
       "      <td>0.124877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110356</td>\n",
       "      <td>-0.137992</td>\n",
       "      <td>0.201295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.470527</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664881</td>\n",
       "      <td>0.388296</td>\n",
       "      <td>-0.492861</td>\n",
       "      <td>0.414489</td>\n",
       "      <td>0.046847</td>\n",
       "      <td>0.430552</td>\n",
       "      <td>0.518430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331662</td>\n",
       "      <td>0.208081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.788529</td>\n",
       "      <td>-0.146522</td>\n",
       "      <td>0.068939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614697</td>\n",
       "      <td>-0.352913</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.141435</td>\n",
       "      <td>0.156426</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>-0.124727</td>\n",
       "      <td>0.376917</td>\n",
       "      <td>0.092540</td>\n",
       "      <td>-0.603993</td>\n",
       "      <td>-2.439421</td>\n",
       "      <td>0.233077</td>\n",
       "      <td>-0.024996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>0.231163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.249299</td>\n",
       "      <td>0.079554</td>\n",
       "      <td>-0.354898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.319763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.555840</td>\n",
       "      <td>0.596420</td>\n",
       "      <td>0.787524</td>\n",
       "      <td>0.674778</td>\n",
       "      <td>0.421446</td>\n",
       "      <td>-0.551402</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.619562</td>\n",
       "      <td>0.456220</td>\n",
       "      <td>0.841233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280245</td>\n",
       "      <td>0.402004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.159438</td>\n",
       "      <td>0.071524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208653</td>\n",
       "      <td>0.428462</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.824748</td>\n",
       "      <td>0.702370</td>\n",
       "      <td>1.138450</td>\n",
       "      <td>0.799166</td>\n",
       "      <td>-0.473129</td>\n",
       "      <td>-0.477812</td>\n",
       "      <td>0.829788</td>\n",
       "      <td>0.296930</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823074</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.320227</td>\n",
       "      <td>0.106041</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060961</td>\n",
       "      <td>0.052468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 1836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P02768    P02787    P01009    P01024    P0C0L5    P02649    P0DOY2  \\\n",
       "0  -0.072897  0.181743  0.402426  0.184709  0.701173 -0.137677 -0.193675   \n",
       "1   0.768857  0.558457  0.379343  0.441253  0.288571  0.000000 -0.524307   \n",
       "2  -0.028010 -0.133621 -0.309150 -0.044071  0.438521 -0.164236  0.063932   \n",
       "3   0.377361  0.403682  0.216778  0.722584  0.270382 -0.243587  0.327541   \n",
       "4  -0.081855  0.075107  0.072067  0.104687 -0.154194  0.247885 -0.479686   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "80 -0.764546 -0.285425  0.000000 -0.390569  0.105446  0.218675 -0.974621   \n",
       "81  0.470527  0.447341  0.000000  0.664881  0.388296 -0.492861  0.414489   \n",
       "82 -0.141435  0.156426  0.007050 -0.124727  0.376917  0.092540 -0.603993   \n",
       "83  0.555840  0.596420  0.787524  0.674778  0.421446 -0.551402  0.381700   \n",
       "84  0.824748  0.702370  1.138450  0.799166 -0.473129 -0.477812  0.829788   \n",
       "\n",
       "      P00738    P06396    P02647  ...    Q9NVA2    Q08257    Q56P03    Q9UJ90  \\\n",
       "0   0.659157  0.227605 -0.337082  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   2.072155  0.279783  0.679007  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.849340  0.121026 -0.203564  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   1.936260 -0.069995  1.361930  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  -0.306355  0.169838 -0.299773  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "80 -3.342641 -0.118785  0.000000  ...  0.243559 -0.058127  1.359753 -0.065500   \n",
       "81  0.046847  0.430552  0.518430  ...  0.331662  0.208081  0.000000 -0.788529   \n",
       "82 -2.439421  0.233077 -0.024996  ... -0.283738  0.231163  0.000000 -0.249299   \n",
       "83  0.619562  0.456220  0.841233  ...  0.280245  0.402004  0.000000  0.000000   \n",
       "84  0.296930  0.367581  0.000000  ...  0.823074  0.737500  0.000000 -0.320227   \n",
       "\n",
       "      P31948    P05107  O95196    O75339    O14960    Q07812  \n",
       "0   0.000000  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "..       ...       ...     ...       ...       ...       ...  \n",
       "80 -0.440303  0.124877     0.0 -1.110356 -0.137992  0.201295  \n",
       "81 -0.146522  0.068939     0.0  0.614697 -0.352913  0.000000  \n",
       "82  0.079554 -0.354898     0.0 -0.319763  0.000000  0.000000  \n",
       "83 -0.159438  0.071524     0.0  0.208653  0.428462  0.000000  \n",
       "84  0.106041  0.147222     0.0 -0.060961  0.052468  0.000000  \n",
       "\n",
       "[85 rows x 1836 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zero_impute = pd.read_csv(\"./Data/data files/Lumbar_ToImpute.csv\")\n",
    "df_zero_impute.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "df_zero_impute.fillna(0, inplace=True)\n",
    "df_zero_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Data/data files/imputed\"\n",
    "starts_with = \"protein_lumbar\"\n",
    "dfs = import_csv_files(path=path, starts_with=starts_with)\n",
    "X = get_average_from_m_datasets(dfs)\n",
    "\n",
    "#df_imputed = pd.read_csv(\"./Data/data files/imputed/df_protein_lumbar_imputed_75_5_etr.csv\")\n",
    "#X = df_imputed.to_numpy()\n",
    "df_classes = pd.read_csv(\"./Data/data files/iNPH_data_protein_median.csv\", usecols=[\"Cortical_biopsy_grouping\", \"CSF_type\", \"TMT Set\"])\n",
    "df_classes = df_classes[df_classes[\"CSF_type\"] == \"L\"].reset_index(drop=True)\n",
    "tmt_set = df_classes[\"TMT Set\"]\n",
    "y = df_classes[\"Cortical_biopsy_grouping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_combat(df, TMT_set_indices):\n",
    "    \"\"\"Run ComBat to reduce batch effect on a dataframe.\n",
    "\n",
    "    :param df: Dataframe that ComBat is runned on\n",
    "    :param TMT_set_indices: Labels of which TMT batch each row belongs to.\n",
    "    :return: DF with ComBat applied to it\n",
    "    \"\"\"    \n",
    "    return pycombat(df.T, TMT_set_indices).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(df, n_samples, std = 0.1):\n",
    "    \"\"\"Helper function for simple perturbation function. Adds gaussian noise to randomly sampled rows of the df passed as an argument.\n",
    "\n",
    "    :param df: df filtered on class\n",
    "    :param n_samples: Number of samples to perform random sampling on\n",
    "    :param std: Standard deviation. Defaults to 0.1.\n",
    "    :return: df with added perturbed samples\n",
    "    \"\"\"      \n",
    "    sampled_df = df.sample(n = n_samples, replace = True)\n",
    "    gaussian_noise = np.random.normal(0, std, size=sampled_df.shape)\n",
    "    return sampled_df + gaussian_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def simple_perturbation(X, y, n_samples_per_class = None, std = 0.1):\n",
    "    \"\"\"Performs a simple perturbation by sampling random rows of classes and adds gaussian noise to them\n",
    "\n",
    "    :param X: Dataframe with samples to get perturbed\n",
    "    :param y: Class labels\n",
    "    :param n_samples_per_class: Decides how many samples per class that are going to be sampled, defaults to None. \n",
    "    If none -> all classes will get equal weight according to size of current largest class.\n",
    "    :param std: How much the noise can deviate from the mean (Standard dev.), defaults to 0.1\n",
    "    :return: A df with the perturbed samples. A list stating which row belongs to which class.\n",
    "    \"\"\"    \n",
    "    classes = y.value_counts()\n",
    "    if n_samples_per_class is None:\n",
    "        largest_class = classes.argmax()\n",
    "        largest_n_samples = classes.pop(largest_class)\n",
    "    else:\n",
    "        largest_n_samples = n_samples_per_class\n",
    "    df_list = []\n",
    "    y_new_classes = list(y)\n",
    "    for idx, n_samples in classes.items():\n",
    "        perturbed = add_noise(X[y == idx], largest_n_samples - n_samples, std=std)\n",
    "        df_list.append(perturbed)\n",
    "        y_new_classes = y_new_classes + [idx] * len(perturbed)\n",
    "    return pd.concat([X] + df_list, axis=0), y_new_classes#, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()\n",
    "xgboost.name = \"XGBoost\"\n",
    "lr = LogisticRegression()\n",
    "lr.name = \"LogisticRegression\"\n",
    "rf = RandomForestClassifier()\n",
    "rf.name = \"RandomForest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgboost_params = {\"min_child_weight\": [1, 5, 10],\n",
    "                  \"gamma\": [0.5, 1, 1,5, 2, 5],\n",
    "                  \"subsample\": [0.6, 0.8, 1.0],\n",
    "                  \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "                  \"max_depth\": [3, 4, 5],\n",
    "                  \"n_estimators\": [100, 500, 1000]}\n",
    "lr_params = [{\"penalty\": [\"l1\"],\n",
    "              \"C\": np.arange(0.2, 3.1, 0.2),\n",
    "              \"solver\": [\"saga\"],\n",
    "              \"multi_class\": [\"multinomial\"],\n",
    "              \"max_iter\": np.arange(1000, 10001, 2000)\n",
    "             }]\n",
    "rf_params = {\"n_estimators\": np.arange(100, 501, 100),\n",
    "             \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "             \"max_depth\": [None, 10, 20, 40],\n",
    "             \"max_features\": [\"sqrt\", \"log2\"],\n",
    "             \"min_samples_leaf\": [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#models = [xgboost, lr, rf]\n",
    "#params = [xgboost_params, lr_params, rf_params]\n",
    "\n",
    "lr_params = [{\"penalty\": [\"l1\"],\n",
    "              \"C\": np.arange(0.2, 0.5),\n",
    "              \"solver\": [\"saga\"],\n",
    "              \"multi_class\": [\"multinomial\"],\n",
    "              \"max_iter\": [1000]}]\n",
    "rf_params = {\"n_estimators\": np.arange(100, 501, 100),\n",
    "             \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "             \"max_depth\": [None, 10, 20, 40],\n",
    "             \"max_features\": [\"log2\"],\n",
    "             \"min_samples_leaf\": [1, 2]}\n",
    "models = [rf]\n",
    "params = [rf_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_pt1(X, df_classes, csf_type, n_samples_per_class = 100, do_combat = True, do_std_scaler = True,):\n",
    "    type = df_classes[df_classes[\"CSF_type\"] == csf_type].reset_index(drop=True)\n",
    "    y = type[\"Cortical_biopsy_grouping\"]\n",
    "    tmt_set = type[\"TMT Set\"].values\n",
    "    if do_combat:\n",
    "        X = run_combat(X, tmt_set)\n",
    "    X, y = simple_perturbation(X, y, n_samples_per_class = n_samples_per_class)\n",
    "    if do_std_scaler:\n",
    "        std_scaler = StandardScaler()\n",
    "        X = std_scaler.fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_params(X, y, models, params, cv = 5, n_jobs = -1):\n",
    "    best_params = {}\n",
    "    for model, param in zip(models, params):\n",
    "        start_time = time()\n",
    "        print(f\"{model.name} started.\")\n",
    "        clf = GridSearchCV(model, param_grid=param, cv=cv, n_jobs=n_jobs, scoring=\"f1_weighted\")\n",
    "        clf.fit(X, y)\n",
    "        best_params[model.name] = clf.best_params_\n",
    "        print(f\"{model.name} is done in {time() - start_time} seconds.\\n\" )\n",
    "    return best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_pt3(X, y, models, params, tmt_set = None, K = 5, n_samples_per_class = 100):\n",
    "    X = run_combat(X, tmt_set)\n",
    "    k_fold = StratifiedKFold(n_splits=K, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(k_fold.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train, y_train = simple_perturbation(X_train, y_train, n_samples_per_class=n_samples_per_class)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        print(f'Fold: {i}')\n",
    "        print(f'Train: {train_index}')\n",
    "        print(f'Test: {test_index}')\n",
    "        #for model in models:\n",
    "            #pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True)\n",
    "k_fold.get_n_splits(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 11, 13, 23, 34, 42, 46, 49, 55, 56, 57, 61, 65, 71, 74, 75, 82])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_k_fold = StratifiedKFold(n_splits=5, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def pipeline(X, y, models, params, tmt_set = None, K = 5, n_samples_per_class = 100):\n",
    "    X = run_combat(X, tmt_set)\n",
    "    k_fold = StratifiedKFold(n_splits=K, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        X_train, y_train = simple_perturbation(X_train, y_train, n_samples_per_class=n_samples_per_class)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        best_params = get_best_params(X_train, y_train, models, params)\n",
    "        for model in models:\n",
    "            best_model = model.__class__(**best_params[model.name])\n",
    "            best_model.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            print(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n",
      "Adjusting the Data\n",
      "RandomForest started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/combat/pycombat.py:159: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.absolute(d_new-d_old)/d_old))  # maximum difference between new and old estimate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest is done in 31.84743595123291 seconds.\n",
      "\n",
      "0.33137254901960783\n",
      "RandomForest started.\n",
      "RandomForest is done in 32.050607204437256 seconds.\n",
      "\n",
      "0.17337461300309598\n",
      "RandomForest started.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oscarrosberg/Documents/Applied Data Science/Thesis/Project/ModelsPipeline.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline(df_zero_impute, y, models, params, tmt_set)\n",
      "\u001b[1;32m/Users/oscarrosberg/Documents/Applied Data Science/Thesis/Project/ModelsPipeline.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m best_params \u001b[39m=\u001b[39m get_best_params(X_train, y_train, models, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     best_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params[model\u001b[39m.\u001b[39mname])\n",
      "\u001b[1;32m/Users/oscarrosberg/Documents/Applied Data Science/Thesis/Project/ModelsPipeline.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m started.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m clf \u001b[39m=\u001b[39m GridSearchCV(model, param_grid\u001b[39m=\u001b[39mparam, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39mn_jobs, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf1_weighted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m best_params[model\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oscarrosberg/Documents/Applied%20Data%20Science/Thesis/Project/ModelsPipeline.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m is done in \u001b[39m\u001b[39m{\u001b[39;00mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline(X, y, models, params, tmt_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
